{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "testing.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "qpb3FrPDlk5B",
        "PBfXhLDulsqQ",
        "aXPxJF7_lwn9",
        "nI2ooQW3HAsK",
        "WAGMyzAWQFZ3",
        "SuU0tNgBwjRb"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "hldfM3m2Vk36"
      },
      "source": [
        "# !sudo add-apt-repository ppa:ubuntu-toolchain-r/test \n",
        "# !sudo apt-get update\n",
        "# !sudo apt-get upgrade\n",
        "# !sudo apt-get dist-upgrade"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZxGUKyUlN9Mh"
      },
      "source": [
        "# !pip install coremltools==5.0b2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-bWZePl7CP0e"
      },
      "source": [
        "# System details"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wFtAGFrVCWS_"
      },
      "source": [
        "!nvidia-smi -L"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fV_HtbsdCW_W"
      },
      "source": [
        "!lscpu |grep 'Model name'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sSNPcQNqXn2P"
      },
      "source": [
        "# Dataset setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BfK0zDFW4OoG"
      },
      "source": [
        "import random\n",
        "import os\n",
        "import shutil"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vX6CxXP7XsIt"
      },
      "source": [
        "## Dataset download"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dotlK6QxZB1m"
      },
      "source": [
        "!git clone https://github.com/spMohanty/PlantVillage-Dataset.git "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eNklV0JNbTUy"
      },
      "source": [
        "!mkdir Dataset\n",
        "!mkdir Dataset/Color\n",
        "!mkdir Dataset/Grayscale\n",
        "!mkdir Dataset/Segmented\n",
        "\n",
        "!mkdir Dataset/Color/Training\n",
        "!mkdir Dataset/Grayscale/Training\n",
        "!mkdir Dataset/Segmented/Training\n",
        "\n",
        "!mkdir Dataset/Color/Training/Black_rot\n",
        "!mkdir Dataset/Color/Training/Leaf_blight\n",
        "!mkdir Dataset/Color/Training/Esca\n",
        "!mkdir Dataset/Color/Training/Healthy\n",
        "\n",
        "!mkdir Dataset/Grayscale/Training/Black_rot\n",
        "!mkdir Dataset/Grayscale/Training/Leaf_blight\n",
        "!mkdir Dataset/Grayscale/Training/Esca\n",
        "!mkdir Dataset/Grayscale/Training/Healthy\n",
        "\n",
        "!mkdir Dataset/Segmented/Training/Black_rot\n",
        "!mkdir Dataset/Segmented/Training/Leaf_blight\n",
        "!mkdir Dataset/Segmented/Training/Esca\n",
        "!mkdir Dataset/Segmented/Training/Healthy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uBRmkR26cZuO"
      },
      "source": [
        "def move_files(source_folder, destination_folder):\n",
        "    total_images = len(os.listdir(source_folder))\n",
        "    images_moved = 0\n",
        "    for file_name in os.listdir(source_folder):\n",
        "        # construct full file path\n",
        "        source = os.path.join(source_folder, file_name)\n",
        "        destination = os.path.join(destination_folder, file_name)\n",
        "        # move only files\n",
        "        if os.path.isfile(source):\n",
        "            shutil.move(source, destination)\n",
        "            images_moved += 1\n",
        "    print(f\"{images_moved}/{total_images}\")\n",
        "    print(\"Images moved\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_zsI3BcdPA6"
      },
      "source": [
        "# Color\n",
        "move_files(\"/content/PlantVillage-Dataset/raw/color/Grape___Black_rot\", \"/content/Dataset/Color/Training/Black_rot\")\n",
        "move_files(\"/content/PlantVillage-Dataset/raw/color/Grape___Esca_(Black_Measles)\",\"/content/Dataset/Color/Training/Esca\")\n",
        "move_files(\"/content/PlantVillage-Dataset/raw/color/Grape___healthy\",\"/content/Dataset/Color/Training/Healthy\")\n",
        "move_files(\"/content/PlantVillage-Dataset/raw/color/Grape___Leaf_blight_(Isariopsis_Leaf_Spot)\",\"/content/Dataset/Color/Training/Leaf_blight\")\n",
        "\n",
        "# Grayscale\n",
        "move_files(\"/content/PlantVillage-Dataset/raw/grayscale/Grape___Black_rot\", \"/content/Dataset/Grayscale/Training/Black_rot\")\n",
        "move_files(\"/content/PlantVillage-Dataset/raw/grayscale/Grape___Esca_(Black_Measles)\",\"/content/Dataset/Grayscale/Training/Esca\")\n",
        "move_files(\"/content/PlantVillage-Dataset/raw/grayscale/Grape___healthy\",\"/content/Dataset/Grayscale/Training/Healthy\")\n",
        "move_files(\"/content/PlantVillage-Dataset/raw/grayscale/Grape___Leaf_blight_(Isariopsis_Leaf_Spot)\",\"/content/Dataset/Grayscale/Training/Leaf_blight\")\n",
        "\n",
        "# Segmented\n",
        "move_files(\"/content/PlantVillage-Dataset/raw/segmented/Grape___Black_rot\", \"/content/Dataset/Segmented/Training/Black_rot\")\n",
        "move_files(\"/content/PlantVillage-Dataset/raw/segmented/Grape___Esca_(Black_Measles)\",\"/content/Dataset/Segmented/Training/Esca\")\n",
        "move_files(\"/content/PlantVillage-Dataset/raw/segmented/Grape___healthy\",\"/content/Dataset/Segmented/Training/Healthy\")\n",
        "move_files(\"/content/PlantVillage-Dataset/raw/segmented/Grape___Leaf_blight_(Isariopsis_Leaf_Spot)\",\"/content/Dataset/Segmented/Training/Leaf_blight\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFwIntTDddRE"
      },
      "source": [
        "!rm -rf /content/PlantVillage-Dataset\n",
        "!rm -rf /content/sample_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZeM9dK0tY-q"
      },
      "source": [
        "## Setting up training, validation and testing dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flmED_KK0UP7"
      },
      "source": [
        "num_images = [[i, len(os.listdir(os.path.join(\"/content/Dataset/Color/Training\", i)))] for i in os.listdir(\"/content/Dataset/Color/Training\")]\n",
        "print(f\"Number of training images in Color folder {num_images}\")\n",
        "\n",
        "num_images = [[i, len(os.listdir(os.path.join(\"/content/Dataset/Grayscale/Training\", i)))] for i in os.listdir(\"/content/Dataset/Color/Training\")]\n",
        "print(f\"Number of training images in Grayscale folder {num_images}\")\n",
        "\n",
        "num_images = [[i, len(os.listdir(os.path.join(\"/content/Dataset/Segmented/Training\", i)))] for i in os.listdir(\"/content/Dataset/Color/Training\")]\n",
        "print(f\"Number of training images in Segmented folder {num_images}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQgZWlYhtjq4"
      },
      "source": [
        "def create_folder(source, fol_name,factor):\n",
        "  classes = os.listdir(source)\n",
        "  for cl in classes:\n",
        "      file_path = os.path.join(source,cl)\n",
        "      exist = False\n",
        "      exist = [True for fol in os.listdir(os.path.join(os.curdir,fol_name)) if fol==cl]\n",
        "      path1 = os.path.join(os.curdir,fol_name,cl)\n",
        "      if(len(exist) == 0):\n",
        "          os.mkdir(path1)\n",
        "\n",
        "          res = os.listdir(file_path)\n",
        "          val = int(len(res) * factor)\n",
        "          imgList = random.sample(range(0, len(res)), val)\n",
        "\n",
        "          for index in imgList:\n",
        "              shutil.move(os.path.join(file_path,res[index]), path1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E4-fv_IDzGYZ"
      },
      "source": [
        "!mkdir /content/Dataset/Color/Validation\n",
        "!mkdir /content/Dataset/Color/Test\n",
        "\n",
        "!mkdir /content/Dataset/Grayscale/Validation\n",
        "!mkdir /content/Dataset/Grayscale/Test\n",
        "\n",
        "!mkdir /content/Dataset/Segmented/Validation\n",
        "!mkdir /content/Dataset/Segmented/Test\n",
        "\n",
        "\n",
        "create_folder(\"/content/Dataset/Color/Training\", \"/content/Dataset/Color/Validation\",0.1)\n",
        "create_folder(\"/content/Dataset/Color/Training\", \"/content/Dataset/Color/Test\",0.2)\n",
        "\n",
        "create_folder(\"/content/Dataset/Grayscale/Training\", \"/content/Dataset/Grayscale/Validation\",0.1)\n",
        "create_folder(\"/content/Dataset/Grayscale/Training\", \"/content/Dataset/Grayscale/Test\",0.2)\n",
        "\n",
        "\n",
        "create_folder(\"/content/Dataset/Segmented/Training\", \"/content/Dataset/Segmented/Validation\",0.1)\n",
        "create_folder(\"/content/Dataset/Segmented/Training\", \"/content/Dataset/Segmented/Test\",0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3lVlDCB4Z-Y"
      },
      "source": [
        "## Dataset info"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZG7Ujen3N2w"
      },
      "source": [
        "# Confirming the division of training, testing and validation dataset\n",
        "\n",
        "print(\"Color\")\n",
        "num_images = [[i, len(os.listdir(os.path.join(\"/content/Dataset/Color/Training\", i)))] for i in os.listdir(\"/content/Dataset/Color/Training\")]\n",
        "total = 0\n",
        "for i in num_images:\n",
        "    total += i[1]\n",
        "print(f\"Number of training images in Color folder {num_images}\")\n",
        "print(f\"Total: {total}\")\n",
        "\n",
        "num_images = [[i, len(os.listdir(os.path.join(\"/content/Dataset/Color/Validation\", i)))] for i in os.listdir(\"/content/Dataset/Color/Validation\")]\n",
        "total = 0\n",
        "for i in num_images:\n",
        "    total += i[1]\n",
        "print(f\"Number of validation images in Color folder {num_images}\")\n",
        "print(f\"Total: {total}\")\n",
        "\n",
        "num_images = [[i, len(os.listdir(os.path.join(\"/content/Dataset/Color/Test\", i)))] for i in os.listdir(\"/content/Dataset/Color/Test\")]\n",
        "total = 0\n",
        "for i in num_images:\n",
        "    total += i[1]\n",
        "print(f\"Number of testing images in Color folder {num_images}\")\n",
        "print(f\"Total: {total}\")\n",
        "\n",
        "print(\"----------------------\")\n",
        "print(\"Grayscale\")\n",
        "num_images = [[i, len(os.listdir(os.path.join(\"/content/Dataset/Grayscale/Training\", i)))] for i in os.listdir(\"/content/Dataset/Grayscale/Training\")]\n",
        "total = 0\n",
        "for i in num_images:\n",
        "    total += i[1]\n",
        "print(f\"Number of training images in Grayscale folder {num_images}\")\n",
        "print(f\"Total: {total}\")\n",
        "\n",
        "num_images = [[i, len(os.listdir(os.path.join(\"/content/Dataset/Grayscale/Validation\", i)))] for i in os.listdir(\"/content/Dataset/Grayscale/Validation\")]\n",
        "total = 0\n",
        "for i in num_images:\n",
        "    total += i[1]\n",
        "print(f\"Number of validation images in Grayscale folder {num_images}\")\n",
        "print(f\"Total: {total}\")\n",
        "\n",
        "num_images = [[i, len(os.listdir(os.path.join(\"/content/Dataset/Grayscale/Test\", i)))] for i in os.listdir(\"/content/Dataset/Grayscale/Test\")]\n",
        "total = 0\n",
        "for i in num_images:\n",
        "    total += i[1]\n",
        "print(f\"Number of testing images in Grayscale folder {num_images}\")\n",
        "print(f\"Total: {total}\")\n",
        "\n",
        "print(\"----------------------\")\n",
        "print(\"Segmented\")\n",
        "num_images = [[i, len(os.listdir(os.path.join(\"/content/Dataset/Segmented/Training\", i)))] for i in os.listdir(\"/content/Dataset/Segmented/Training\")]\n",
        "total = 0\n",
        "for i in num_images:\n",
        "    total += i[1]\n",
        "print(f\"Number of training images in Segmented folder {num_images}\")\n",
        "print(f\"Total: {total}\")\n",
        "\n",
        "num_images = [[i, len(os.listdir(os.path.join(\"/content/Dataset/Segmented/Validation\", i)))] for i in os.listdir(\"/content/Dataset/Segmented/Validation\")]\n",
        "total = 0\n",
        "for i in num_images:\n",
        "    total += i[1]\n",
        "print(f\"Number of validation images in Segmented folder {num_images}\")\n",
        "print(f\"Total: {total}\")\n",
        "\n",
        "num_images = [[i, len(os.listdir(os.path.join(\"/content/Dataset/Segmented/Test\", i)))] for i in os.listdir(\"/content/Dataset/Segmented/Test\")]\n",
        "total = 0\n",
        "for i in num_images:\n",
        "    total += i[1]\n",
        "print(f\"Number of testing images in Segmented folder {num_images}\")\n",
        "print(f\"Total: {total}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2K9BN8Ak6wOQ"
      },
      "source": [
        "# Dataset preprocessing and augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMTYKXqS69Jw"
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from matplotlib import pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qpb3FrPDlk5B"
      },
      "source": [
        "#### No augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2YfYl_l1giu_"
      },
      "source": [
        "# def to_tensor(pil):\n",
        "#     return torch.tensor(np.array(pil)).permute(2,0,1).float()\n",
        "# t = transforms.Compose([\n",
        "#                         transforms.Resize((256, 256)),\n",
        "#                         transforms.Lambda(to_tensor)\n",
        "#                         ])\n",
        "\n",
        "# train_dataloader = torchvision.datasets.ImageFolder(\"/content/Dataset/Color/Training\", t)\n",
        "# train_dataloader = DataLoader(train_dataloader, batch_size = 32, shuffle=True)\n",
        "\n",
        "# validation_dataloader = torchvision.datasets.ImageFolder(\"/content/Dataset/Color/Validation\", t)\n",
        "# validation_dataloader = DataLoader(validation_dataloader, batch_size = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PBfXhLDulsqQ"
      },
      "source": [
        "#### Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L47h06sxl0Jv"
      },
      "source": [
        "def to_tensor(pil):\n",
        "    return torch.tensor(np.array(pil)).permute(2,0,1).float()\n",
        "t = transforms.Compose([\n",
        "                        transforms.Resize((256, 256)),\n",
        "                        transforms.RandomHorizontalFlip(p=0.5),\n",
        "                        transforms.RandomRotation(90),\n",
        "                        transforms.RandomRotation(180),\n",
        "                        transforms.RandomRotation(270),\n",
        "                        transforms.RandomVerticalFlip(p=0.5),\n",
        "                        transforms.Lambda(to_tensor)\n",
        "                        ])\n",
        "\n",
        "train_dataloader = torchvision.datasets.ImageFolder(\"/content/Dataset/Color/Training\", t)\n",
        "train_dataloader = DataLoader(train_dataloader, batch_size = 32, shuffle=True)\n",
        "\n",
        "validation_dataloader = torchvision.datasets.ImageFolder(\"/content/Dataset/Color/Validation\", t)\n",
        "validation_dataloader = DataLoader(validation_dataloader, batch_size = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMvxvFN_ncvI"
      },
      "source": [
        "# count = 0\n",
        "# for inputs, labels in train_dataloader:\n",
        "#     count += 1\n",
        "# count*32"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aXPxJF7_lwn9"
      },
      "source": [
        "#### Dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IjlSgvJJIT-G"
      },
      "source": [
        "dataloaders = {'train':train_dataloader, 'val':validation_dataloader}\n",
        "dataset_sizes = {'train':2927, 'val': 405}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dts_Ybpl_Uf"
      },
      "source": [
        "# Display image and label.\n",
        "train_features, train_labels = next(iter(train_dataloader))\n",
        "print(f\"Feature batch shape: {train_features.size()}\")\n",
        "print(f\"Labels batch shape: {train_labels.size()}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aByFB6DnAkvY"
      },
      "source": [
        "# Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZOnLCQkqAnJ3"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import numpy as np\n",
        "import torchvision\n",
        "import torchvision.models as models\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HKRMEPc0G9Y5"
      },
      "source": [
        "## Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nI2ooQW3HAsK"
      },
      "source": [
        "### Resnet18"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SjrX3WCiAvFY"
      },
      "source": [
        "resnet18 = models.resnet18(pretrained=True)\n",
        "resnet18.to('cuda')\n",
        "resnet18.fc.out_features = 4\n",
        "print(resnet18)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WAGMyzAWQFZ3"
      },
      "source": [
        "### Mobilenet_v2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VOF96xMSdelQ"
      },
      "source": [
        "# mobilenet_v2 = models.mobilenet_v2(pretrained=True)\n",
        "# mobilenet_v2.to('cuda')\n",
        "# mobilenet_v2.classifier[1].out_features = 4\n",
        "# print(mobilenet_v2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fDHdCO_QHDZV"
      },
      "source": [
        "## Optimiser and scheduler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utGos7EtCR-4"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(resnet18.parameters(), lr=0.001, momentum=0.9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJUHiJePeaDN"
      },
      "source": [
        "# criterion = nn.CrossEntropyLoss()\n",
        "# optimizer = optim.SGD(mobilenet_v2.parameters(), lr=0.001, momentum=0.9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sgcm3v7KHIJK"
      },
      "source": [
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WO_jfaQwHI6P"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_L8n4Ez7EHkl"
      },
      "source": [
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=25, device='cuda'):\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "            if phase == 'train':\n",
        "                scheduler.step()\n",
        "\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "                phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ZnUsdH-G5aI"
      },
      "source": [
        "model = train_model(resnet18, criterion, optimizer, exp_lr_scheduler, num_epochs=25)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5qx_ebFeIEL"
      },
      "source": [
        "# model = train_model(mobilenet_v2, criterion, optimizer, exp_lr_scheduler, num_epochs=25)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SuU0tNgBwjRb"
      },
      "source": [
        "### Model testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ymiFuJuuyF-E"
      },
      "source": [
        "from sklearn.metrics import precision_score,recall_score, f1_score, accuracy_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ru3j-6AtyH3D"
      },
      "source": [
        "def to_tensor(pil):\n",
        "    return torch.tensor(np.array(pil)).permute(2,0,1).float()\n",
        "t = transforms.Compose([\n",
        "                        transforms.Resize((256, 256)),\n",
        "                        transforms.Lambda(to_tensor)\n",
        "                        ])\n",
        "\n",
        "test_dataloader = torchvision.datasets.ImageFolder(\"/content/Dataset/Color/Test\", t)\n",
        "test_dataloader = DataLoader(test_dataloader, batch_size = 1, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jvMxVMYFwmZA"
      },
      "source": [
        "def model_testing(model, dataloader):\n",
        "    model.eval()\n",
        "    op = []\n",
        "    gt = []\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in dataloader:\n",
        "            inputs = inputs.to('cuda')\n",
        "            labels = labels.to('cuda')\n",
        "            output = model(inputs)\n",
        "            _, preds = torch.max(output, 1)\n",
        "            op.append(preds.detach().cpu().numpy()[0])\n",
        "            gt.append(labels.item())\n",
        "    \n",
        "    prec = precision_score(gt, op, average=None)\n",
        "    rec = recall_score(gt, op, average=None)\n",
        "    f1 = f1_score(gt, op, average=None)\n",
        "    acc = accuracy_score(gt,op)\n",
        "    print(f\"Precision: {prec}\")\n",
        "    print(f\"Recall: {rec}\")\n",
        "    print(f\"F1 Score: {f1}\")\n",
        "    print(f\"Accuracy: {acc}\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-NqpiCnL28Y"
      },
      "source": [
        "print(test_dataloader.dataset.class_to_idx)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3NK2-d6syVDI"
      },
      "source": [
        "model_testing(model, test_dataloader)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6OEP_2uvOSrK"
      },
      "source": [
        "## Save model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6SRgBnGNc1Z"
      },
      "source": [
        "# import coremltools as ct"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qlqVEV7xOSVG"
      },
      "source": [
        "# torch.save(model, \"grape_classification.pt\") # In PyTorch format"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AsZgsBrTL9H2"
      },
      "source": [
        "# for example_input, labels in dataloaders['val']:\n",
        "#     example_input = example_input.to('cuda')\n",
        "#     break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ap6urmQ5LbkF"
      },
      "source": [
        "# model.eval()\n",
        "# trace = torch.jit.trace(model, example_input)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g65ZvXGWODUj"
      },
      "source": [
        "# # Convert to Core ML using the Unified Conversion API\n",
        "# model = ct.convert(\n",
        "#     trace,\n",
        "#     inputs=[ct.ImageType(name=\"input_1\", shape=example_input.shape)],\n",
        "# )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3Isxf1yWKTl"
      },
      "source": [
        "# model.save(\"GrapeDiseaseDetectionMNV2.mlmodel\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}